{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "from langchain.agents import Tool, AgentExecutor\n",
    "from langchain.agents.react.base import ReActDocstoreAgent\n",
    "from langchain.llms.openai import AzureOpenAI\n",
    "from langchain.prompts import PromptTemplate, BasePromptTemplate\n",
    "from typing import List\n",
    "\n",
    "# Replace these with your own values, either in environment variables or directly here\n",
    "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\") or \"mystorageaccount\"\n",
    "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\") or \"content\"\n",
    "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\") or \"gptkb\"\n",
    "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\") or \"gptkbindex\"\n",
    "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\") or \"myopenai\"\n",
    "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\") or \"davinci\"\n",
    "\n",
    "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\") or \"content\"\n",
    "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\") or \"category\"\n",
    "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\") or \"sourcepage\"\n",
    "\n",
    "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed, \n",
    "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the \n",
    "# keys for each service\n",
    "azure_credential = DefaultAzureCredential()\n",
    "\n",
    "# Used by the OpenAI SDK\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable instead\n",
    "openai.api_type = \"azure_ad\"\n",
    "openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "\n",
    "# Set up clients for Cognitive Search and Storage\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of langchain's ReAct prompt that includes instructions and examples for how to cite information sources\n",
    "\n",
    "EXAMPLES = [\n",
    "    \"\"\"Question: Which type of data should be sent from video cameras in a native binary format?\n",
    "Thought: I need to search Identify data formats, find the Unstructured data.\n",
    "Action: Search[Identify data formats]\n",
    "Observation: <Explore file storage - Training _ Microsoft Learn-2.pdf> According to the source, video data should be sent from video cameras in a native binary format.\n",
    "\"\"\",\n",
    "]\n",
    "SUFFIX = \"\"\"\\nQuestion: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "PREFIX = \"Answer questions as shown in the following examples, by splitting the question into individual search or lookup actions to find facts until you can answer the question. \" \\\n",
    "\"Observations are prefixed by their source name in angled brackets, source names MUST be included with the actions in the answers.\" \\\n",
    "\"All questions must be answered from the results from search or look up actions, only facts resulting from those can be used in an answer. \"\n",
    "\"Answer questions as truthfully as possible, and ONLY answer the questions using the information from observations, do not speculate or your own knowledge.\"\n",
    "\n",
    "prompt = PromptTemplate.from_examples(\n",
    "    EXAMPLES, SUFFIX, [\"input\", \"agent_scratchpad\"], PREFIX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "def search(terms: str):\n",
    "    print (\"\\nsearching: \" + terms)\n",
    "    # Optionally enable captions for summaries by adding optional arugment query_caption=\"extractive|highlight-false\"\n",
    "    # and adjust the string formatting below to include the captions from the @search.captions field\n",
    "    filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "    r = search_client.search(terms, \n",
    "                             filter=filter,\n",
    "                             top = 3,\n",
    "                             query_type=QueryType.SEMANTIC, \n",
    "                             query_language=\"en-us\", \n",
    "                             query_speller=\"lexicon\", \n",
    "                             semantic_configuration_name=\"default\")\n",
    "    return \"\\n\".join([f\"<{doc[KB_FIELDS_SOURCEPAGE]}> \" + (doc[KB_FIELDS_CONTENT][:500]).replace(\"\\n\", \"\").replace(\"\\r\", \"\") for doc in r])\n",
    "\n",
    "def lookup(terms: str):\n",
    "    print (\"\\nlooking up: \" + terms)\n",
    "    filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "    r = search_client.search(terms, \n",
    "                             filter=filter,\n",
    "                             top = 1,\n",
    "                             include_total_count=True,\n",
    "                             query_type=QueryType.SEMANTIC, \n",
    "                             query_language=\"en-us\", \n",
    "                             query_speller=\"lexicon\", \n",
    "                             semantic_configuration_name=\"default\",\n",
    "                             query_answer=\"extractive|count-1\",\n",
    "                             query_caption=\"extractive|highlight-false\")\n",
    "    answers = r.get_answers()\n",
    "    if len(answers) > 0:\n",
    "        return answers[0].text\n",
    "    if r.get_count() > 0:\n",
    "        return \"\\n\".join(c.text for c in next(r)[\"@search.captions\"])\n",
    "    return None\n",
    "\n",
    "llm = AzureOpenAI(deployment_name=AZURE_OPENAI_GPT_DEPLOYMENT, temperature=0.3, openai_api_key=openai.api_key)\n",
    "tools = [\n",
    "    Tool(name=\"Search\", func=search, description=\"useful for when you need to ask with search\"),\n",
    "    Tool(name=\"Lookup\", func=lookup, description=\"useful for when you need to ask with lookup\"  )\n",
    "]\n",
    "\n",
    "class ReAct(ReActDocstoreAgent):\n",
    "    @classmethod\n",
    "    def create_prompt(cls, tools: List[Tool]) -> BasePromptTemplate:\n",
    "        return prompt\n",
    "\n",
    "agent = ReAct.from_llm_and_tools(llm, tools)\n",
    "chain = AgentExecutor.from_agent_and_tools(agent, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "chain.run(\"Ask me a question on DP-900 Microsoft Azure Data Fundamentals\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
